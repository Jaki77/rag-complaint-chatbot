{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1327fbb5",
   "metadata": {},
   "source": [
    "### 1. Import Libraries and Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab04c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Text Chunking, Embedding, and Vector Store Indexing\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path\n",
    "BASE_DIR = Path.cwd().parent\n",
    "sys.path.append(str(BASE_DIR / 'src'))\n",
    "\n",
    "# Import modules\n",
    "from sampling import create_stratified_sample, analyze_sample_quality\n",
    "from chunking import ComplaintChunker, experiment_with_chunking\n",
    "from embedding import EmbeddingModel\n",
    "from vector_store import VectorStore\n",
    "\n",
    "#  Load Cleaned Data\n",
    "print(\"Step 1: Loading cleaned data...\")\n",
    "cleaned_data_path = BASE_DIR / 'data' / 'processed' / 'filtered_complaints.csv'\n",
    "df = pd.read_csv(cleaned_data_path)\n",
    "\n",
    "print(f\"Loaded {len(df):,} cleaned complaints\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f754ba2",
   "metadata": {},
   "source": [
    "### 2. Create Stratified Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26da7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Step 2: Creating stratified sample...\")\n",
    "\n",
    "sampled_df = create_stratified_sample(\n",
    "    df=df,\n",
    "    sample_size=12000,  # Target: 12,000 complaints\n",
    "    stratify_col='Product_standardized',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Analyze sample quality\n",
    "quality_report = analyze_sample_quality(df, sampled_df)\n",
    "print(f\"\\nSample Quality Report:\")\n",
    "print(f\"Mean absolute difference in distribution: {quality_report['mean_absolute_difference']:.2f}%\")\n",
    "print(f\"Coverage: {quality_report['coverage']:.2f}% of original data\")\n",
    "\n",
    "# Save the sample\n",
    "sample_path = BASE_DIR / 'data' / 'processed' / 'stratified_sample.csv'\n",
    "sampled_df.to_csv(sample_path, index=False)\n",
    "print(f\"\\nSample saved to: {sample_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dce190",
   "metadata": {},
   "source": [
    "### 3. Experiment with Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Step 3: Experimenting with chunking parameters...\")\n",
    "\n",
    "# Experiment with different parameters\n",
    "experiment_results = experiment_with_chunking(sampled_df, sample_size=200)\n",
    "print(\"\\nChunking Experiment Results:\")\n",
    "print(experiment_results.to_string())\n",
    "\n",
    "# Visualize experiment results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Chunks per complaint vs chunk size\n",
    "for overlap in experiment_results['chunk_overlap'].unique():\n",
    "    subset = experiment_results[experiment_results['chunk_overlap'] == overlap]\n",
    "    axes[0, 0].plot(subset['chunk_size'], subset['avg_chunks_per_complaint'], \n",
    "                   marker='o', label=f'Overlap={overlap}')\n",
    "axes[0, 0].set_xlabel('Chunk Size')\n",
    "axes[0, 0].set_ylabel('Avg Chunks per Complaint')\n",
    "axes[0, 0].set_title('Chunk Size vs Number of Chunks')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Preservation score\n",
    "for size in experiment_results['chunk_size'].unique():\n",
    "    subset = experiment_results[experiment_results['chunk_size'] == size]\n",
    "    axes[0, 1].plot(subset['chunk_overlap'], subset['preservation_score'], \n",
    "                   marker='s', label=f'Size={size}')\n",
    "axes[0, 1].set_xlabel('Chunk Overlap')\n",
    "axes[0, 1].set_ylabel('Preservation Score')\n",
    "axes[0, 1].set_title('Information Preservation')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Avg chunk length\n",
    "scatter = axes[1, 0].scatter(\n",
    "    experiment_results['chunk_size'],\n",
    "    experiment_results['chunk_overlap'],\n",
    "    c=experiment_results['avg_chunk_length'],\n",
    "    s=experiment_results['avg_chunks_per_complaint'] * 50,\n",
    "    alpha=0.6,\n",
    "    cmap='viridis'\n",
    ")\n",
    "axes[1, 0].set_xlabel('Chunk Size')\n",
    "axes[1, 0].set_ylabel('Chunk Overlap')\n",
    "axes[1, 0].set_title('Chunk Size & Overlap vs Length (size=chunks/complaint)')\n",
    "plt.colorbar(scatter, ax=axes[1, 0], label='Avg Chunk Length')\n",
    "\n",
    "# Plot 4: Choose optimal parameters\n",
    "# Based on experiments, we choose:\n",
    "# - chunk_size = 500 (standard for sentence transformers)\n",
    "# - chunk_overlap = 50 (10% overlap for context preservation)\n",
    "chosen_size = 500\n",
    "chosen_overlap = 50\n",
    "\n",
    "axes[1, 1].axvline(chosen_size, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].axhline(chosen_overlap, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1, 1].scatter(chosen_size, chosen_overlap, color='red', s=200, marker='*', label='Chosen')\n",
    "axes[1, 1].set_xlabel('Chunk Size')\n",
    "axes[1, 1].set_ylabel('Chunk Overlap')\n",
    "axes[1, 1].set_title(f'Chosen Parameters: Size={chosen_size}, Overlap={chosen_overlap}')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(BASE_DIR / 'reports' / 'chunking_experiment.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nChosen chunking parameters:\")\n",
    "print(f\"  - Chunk size: {chosen_size} characters\")\n",
    "print(f\"  - Chunk overlap: {chosen_overlap} characters\")\n",
    "print(f\"  - Rationale: Standard size for sentence transformers, 10% overlap for context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ce8ca",
   "metadata": {},
   "source": [
    "### 4. Chunk All Sampled Complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Step 4: Chunking all sampled complaints...\")\n",
    "\n",
    "chunker = ComplaintChunker(\n",
    "    chunk_size=chosen_size,\n",
    "    chunk_overlap=chosen_overlap\n",
    ")\n",
    "\n",
    "chunks = chunker.chunk_dataframe(sampled_df)\n",
    "\n",
    "# Analyze chunking results\n",
    "chunking_stats = chunker.analyze_chunking_results(chunks, sampled_df)\n",
    "\n",
    "print(f\"\\nChunking Statistics:\")\n",
    "print(f\"  Total chunks: {chunking_stats['total_chunks']:,}\")\n",
    "print(f\"  Total complaints: {chunking_stats['total_complaints']:,}\")\n",
    "print(f\"  Avg chunks per complaint: {chunking_stats['avg_chunks_per_complaint']:.2f}\")\n",
    "print(f\"  Chunk length - Min: {chunking_stats['chunk_length_stats']['min']}\")\n",
    "print(f\"  Chunk length - Max: {chunking_stats['chunk_length_stats']['max']}\")\n",
    "print(f\"  Chunk length - Mean: {chunking_stats['chunk_length_stats']['mean']:.1f}\")\n",
    "print(f\"  Chunk length - Median: {chunking_stats['chunk_length_stats']['median']}\")\n",
    "\n",
    "# Visualize chunk distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Chunk length distribution\n",
    "chunk_lengths = [len(chunk['text']) for chunk in chunks]\n",
    "axes[0].hist(chunk_lengths, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(chosen_size, color='red', linestyle='--', label=f'Target: {chosen_size}')\n",
    "axes[0].set_xlabel('Chunk Length (characters)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Chunk Lengths')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Chunks per complaint distribution\n",
    "chunks_per_complaint = {}\n",
    "for chunk in chunks:\n",
    "    complaint_id = chunk['metadata']['complaint_id']\n",
    "    chunks_per_complaint[complaint_id] = chunks_per_complaint.get(complaint_id, 0) + 1\n",
    "\n",
    "axes[1].hist(list(chunks_per_complaint.values()), bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Chunks per Complaint')\n",
    "axes[1].set_ylabel('Number of Complaints')\n",
    "axes[1].set_title('Distribution of Chunks per Complaint')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(BASE_DIR / 'reports' / 'chunking_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea9a238",
   "metadata": {},
   "source": [
    "### 5. Choose and Initialize Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Step 5: Initializing embedding model...\")\n",
    "\n",
    "model_name = 'all-MiniLM-L6-v2'\n",
    "print(f\"Model choice: {model_name}\")\n",
    "print(\"Reasons for choosing this model:\")\n",
    "print(\"  1. Efficient: Small model (80MB) with good performance\")\n",
    "print(\"  2. Standard: Widely used in RAG applications\")\n",
    "print(\"  3. Balanced: Good trade-off between speed and accuracy\")\n",
    "print(\"  4. Dimension: 384 dimensions - efficient for retrieval\")\n",
    "print(\"  5. Specialized: Trained for semantic similarity tasks\")\n",
    "\n",
    "embedding_model = EmbeddingModel(model_name=model_name)\n",
    "model_info = embedding_model.get_model_info()\n",
    "\n",
    "print(f\"\\nModel Information:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d8773",
   "metadata": {},
   "source": [
    "### 6. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bcf5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Step 6: Generating embeddings for chunks...\")\n",
    "\n",
    "# Extract texts from chunks\n",
    "chunk_texts = [chunk['text'] for chunk in chunks]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = embedding_model.encode(chunk_texts, show_progress=True)\n",
    "\n",
    "print(f\"\\nEmbeddings generated:\")\n",
    "print(f\"  Shape: {embeddings.shape}\")\n",
    "print(f\"  Size: {embeddings.nbytes / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc8f22",
   "metadata": {},
   "source": [
    "### 7. Create and Save Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062faecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Step 7: Creating vector store...\")\n",
    "\n",
    "# Choose vector store type (ChromaDB for development, FAISS for production)\n",
    "store_type = 'chroma'  # or 'faiss'\n",
    "\n",
    "vector_store = VectorStore(\n",
    "    store_type=store_type,\n",
    "    persist_directory=BASE_DIR / 'vector_store' / 'sample',\n",
    "    collection_name='complaint_chunks_sample'\n",
    ")\n",
    "\n",
    "# Create vector store\n",
    "vector_store.create_from_chunks(chunks, embeddings, batch_size=1000)\n",
    "\n",
    "# Get stats\n",
    "stats = vector_store.get_stats()\n",
    "print(f\"\\nVector Store Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ea7d0",
   "metadata": {},
   "source": [
    "### 8. Test Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe213c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Step 8: Testing vector store with sample queries...\")\n",
    "\n",
    "# Sample test queries\n",
    "test_queries = [\n",
    "    \"credit card fees too high\",\n",
    "    \"problems with money transfer\",\n",
    "    \"savings account interest rates\",\n",
    "    \"personal loan application denied\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting retrieval with sample queries:\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    \n",
    "    # Generate query embedding\n",
    "    query_embedding = embedding_model.encode_single(query)\n",
    "    \n",
    "    # Search\n",
    "    results = vector_store.search(query_embedding, k=3)\n",
    "    \n",
    "    print(f\"  Top 3 results:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        product = result['metadata']['product_category']\n",
    "        score = result['score']\n",
    "        text_preview = result['text'][:100] + \"...\" if len(result['text']) > 100 else result['text']\n",
    "        print(f\"    {i}. [{product}] Score: {score:.3f}\")\n",
    "        print(f\"       Text: {text_preview}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162af26c",
   "metadata": {},
   "source": [
    "### 9. Save Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Step 9: Saving configuration...\")\n",
    "\n",
    "config = {\n",
    "    'sampling': {\n",
    "        'sample_size': 12000,\n",
    "        'stratify_column': 'Product_standardized',\n",
    "        'random_state': 42\n",
    "    },\n",
    "    'chunking': {\n",
    "        'chunk_size': chosen_size,\n",
    "        'chunk_overlap': chosen_overlap,\n",
    "        'separators': [\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \", \", \" \", \"\"]\n",
    "    },\n",
    "    'embedding': {\n",
    "        'model_name': model_name,\n",
    "        'embedding_dimension': model_info['embedding_dimension'],\n",
    "        'device': model_info['device']\n",
    "    },\n",
    "    'vector_store': {\n",
    "        'type': store_type,\n",
    "        'persist_directory': str(BASE_DIR / 'vector_store' / 'sample'),\n",
    "        'collection_name': 'complaint_chunks_sample',\n",
    "        'total_chunks': len(chunks)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save config\n",
    "import json\n",
    "config_path = BASE_DIR / 'config' / 'task2_config.json'\n",
    "config_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Configuration saved to: {config_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TASK 2 COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
